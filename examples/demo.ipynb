{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import smplx  \n",
    "import numpy as np  \n",
    "import imageio \n",
    "import os,sys   \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# data = np.load('/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001/smplx/00002_0.npz')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMPLX(\n",
      "  Gender: NEUTRAL\n",
      "  Number of joints: 55\n",
      "  Betas: 10\n",
      "  Number of PCA components: 6\n",
      "  Flat hand mean: False\n",
      "  Number of Expression Coefficients: 10\n",
      "  (vertex_joint_selector): VertexJointSelector()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# orignal demo \n",
    "model_folder = f\"/Users/lxy/Gitlab/smplx/models/smplx/SMPLX_NEUTRAL.npz\"   \n",
    "model_type = 'smplx'\n",
    "gender = 'neutral'\n",
    "use_face_contour = False \n",
    "age = 'adult' \n",
    "num_betas = 10\n",
    "num_expression_coeffs = 10 \n",
    "batch_size = 1 \n",
    "ext = 'npz' \n",
    "sample_shape=True \n",
    "sample_expression=True\n",
    "\n",
    "model1 = smplx.create(model_folder, model_type=model_type,\n",
    "            gender=gender, use_face_contour=use_face_contour,\n",
    "            num_betas=num_betas, num_expression_coeffs=num_expression_coeffs,\n",
    "            ext=ext)  \n",
    "\n",
    "print(model1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smplx_data(npz_path): \n",
    "    \n",
    "    data = np.load(npz_path)\n",
    "    \n",
    "    global_orient = torch.from_numpy(data['global_orient']).reshape(1, -1)  \n",
    "    body_pose = torch.from_numpy(data['body_pose']).reshape(1,-1)\n",
    "    left_hand_pose = torch.from_numpy(data['left_hand_pose']).reshape(1,-1)\n",
    "    right_hand_pose = torch.from_numpy(data['right_hand_pose']).reshape(1,-1)\n",
    "    jaw_pose = torch.from_numpy(data['jaw_pose']).reshape(1,-1)\n",
    "    leye_pose = torch.from_numpy(data['leye_pose']).reshape(1,-1)\n",
    "    reye_pose = torch.from_numpy(data['reye_pose']).reshape(1,-1) \n",
    "    betas = torch.from_numpy(data['betas']).reshape(1,-1)   \n",
    "    expression = torch.from_numpy(data['expression']).reshape(1,-1) \n",
    "    transl = torch.from_numpy(data['transl']).reshape(1,-1)\n",
    "    \n",
    "    return {\n",
    "        'global_orient': global_orient,\n",
    "        'body_pose': body_pose,\n",
    "        'left_hand_pose': left_hand_pose,\n",
    "        'right_hand_pose': right_hand_pose,\n",
    "        'jaw_pose': jaw_pose,\n",
    "        'leye_pose': leye_pose,\n",
    "        'reye_pose': reye_pose,\n",
    "        'betas': betas,\n",
    "        'expression': expression,\n",
    "        'transl': transl\n",
    "    }  \n",
    "\n",
    "# def look_at(eye, target, up):\n",
    "#     f = np.array(target) - np.array(eye)\n",
    "#     f = f / np.linalg.norm(f)\n",
    "#     u = np.array(up)\n",
    "#     s = np.cross(f, u)\n",
    "#     s = s / np.linalg.norm(s)\n",
    "#     u = np.cross(s, f)\n",
    "    \n",
    "#     m = np.eye(4)\n",
    "#     m[0, :3] = s\n",
    "#     m[1, :3] = u\n",
    "#     m[2, :3] = -f\n",
    "#     m[:3, 3] = -m[:3, :3] @ eye\n",
    "\n",
    "#     return m \n",
    "\n",
    "npz_file_path = '/Users/lxy/Desktop/yxl/results/demo00001/smplx/00001_0.npz' \n",
    "data = load_smplx_data(npz_file_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found npz file: /Users/lxy/Desktop/yxl/results/demo00001/smplx/00402_0.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape = (10475, 3)\n",
      "Joints shape = (127, 3)\n",
      "Found npz file: /Users/lxy/Desktop/yxl/results/demo00001/smplx/00890_0.npz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound npz file:\u001b[39m\u001b[38;5;124m\"\u001b[39m, npz_file_path)  \n\u001b[1;32m     38\u001b[0m data \u001b[38;5;241m=\u001b[39m load_smplx_data(npz_file_path)   \n\u001b[0;32m---> 39\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msmplx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_folder\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgender\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_orient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglobal_orient\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleye_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleye_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreye_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreye_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_hand_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft_hand_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_hand_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mright_hand_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaw_pose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjaw_pose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_face_contour\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_face_contour\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_betas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_betas\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_expression_coeffs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_expression_coeffs\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_hand_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mext\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     57\u001b[0m output \u001b[38;5;241m=\u001b[39m model(global_orient\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_orient\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     58\u001b[0m                 betas\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     59\u001b[0m                 expression\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m], return_verts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[1;32m     61\u001b[0m vertices \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:2404\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(model_path, model_type, **kwargs)\u001b[0m\n\u001b[1;32m   2402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SMPLH(model_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmplx\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 2404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSMPLX\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmano\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_type\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m   2406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MANO(model_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_folder = f\"/Users/lxy/Gitlab/smplx/models/smplx/SMPLX_NEUTRAL.npz\"  \n",
    "model_type = 'smplx'\n",
    "gender = 'neutral'\n",
    "use_face_contour = False \n",
    "age = 'adult' \n",
    "num_betas = 10\n",
    "num_expression_coeffs = 10 \n",
    "batch_size = 1 \n",
    "ext = 'npz'\n",
    "\n",
    "sample_shape = None \n",
    "sample_expression = None \n",
    "\n",
    "plotting_module = 'pyrender'  \n",
    "plot_joints = False  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pyrender\n",
    "import trimesh\n",
    "\n",
    "base_directory = '/Users/lxy/Desktop/yxl/results/demo00001'\n",
    "images_directory = os.path.join(base_directory, 'images')\n",
    "\n",
    "# 确保图像保存的目录存在\n",
    "if not os.path.exists(images_directory):\n",
    "    os.makedirs(images_directory)\n",
    "\n",
    "for root, dirs, files in os.walk(base_directory):\n",
    "    if 'smplx' in dirs:\n",
    "        smplx_path = os.path.join(root, 'smplx')\n",
    "        for file in os.listdir(smplx_path):\n",
    "            if file.endswith('.npz'):\n",
    "                npz_file_path = os.path.join(smplx_path, file)\n",
    "                print(\"Found npz file:\", npz_file_path)  \n",
    "\n",
    "                data = load_smplx_data(npz_file_path)   \n",
    "                model = smplx.create(model_folder\n",
    "                                    , model_type=model_type\n",
    "                                    , gender=gender  \n",
    "                                    , global_orient=data['global_orient']\n",
    "                                    , body_pose=data['body_pose']\n",
    "                                    , leye_pose=data['leye_pose']\n",
    "                                    , reye_pose=data['reye_pose'] \n",
    "                                    , left_hand_pose=data['left_hand_pose'] \n",
    "                                    , right_hand_pose=data['right_hand_pose'] \n",
    "                                    , jaw_pose=data['jaw_pose']\n",
    "                                    , transl=data['transl'] \n",
    "                                    , use_pca=False\n",
    "                                    , use_face_contour=use_face_contour\n",
    "                                    , num_betas=num_betas\n",
    "                                    , num_expression_coeffs=num_expression_coeffs\n",
    "                                    , flat_hand_mean=False\n",
    "                                    , ext=ext) \n",
    "\n",
    "                output = model(global_orient=data['global_orient'], \n",
    "                                betas=data['betas'],\n",
    "                                expression=data['expression'], return_verts=True)  \n",
    "\n",
    "                vertices = output.vertices.detach().cpu().numpy().squeeze()\n",
    "                joints = output.joints.detach().cpu().numpy().squeeze()\n",
    "\n",
    "                print('Vertices shape =', vertices.shape)\n",
    "                print('Joints shape =', joints.shape)\n",
    "\n",
    "                vertex_colors = np.ones([vertices.shape[0], 4]) * [0.3, 0.3, 0.3, 0.8]\n",
    "                tri_mesh = trimesh.Trimesh(vertices, model.faces, vertex_colors=vertex_colors)\n",
    "                mesh = pyrender.Mesh.from_trimesh(tri_mesh)\n",
    "                scene = pyrender.Scene()\n",
    "                scene.add(mesh)\n",
    "\n",
    "                if plot_joints:\n",
    "                    sm = trimesh.creation.uv_sphere(radius=0.005)\n",
    "                    sm.visual.vertex_colors = [0.9, 0.1, 0.1, 1.0]\n",
    "                    tfs = np.tile(np.eye(4), (len(joints), 1, 1))\n",
    "                    tfs[:, :3, 3] = joints\n",
    "                    joints_pcl = pyrender.Mesh.from_trimesh(sm, poses=tfs)\n",
    "                    scene.add(joints_pcl)  \n",
    "\n",
    "                # 创建相机\n",
    "                camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0) \n",
    "                camera_pose = np.array([\n",
    "                    [1,     0,     0,      0],\n",
    "                    [0,    -1,     0,      0],\n",
    "                    [0,     0,     1,     20],\n",
    "                    [0,     0,     0,    1.0]\n",
    "                ]) \n",
    "                # scene.add(camera, pose=camera_pose)  \n",
    "                # pyrender.Viewer(scene, use_raymond_lighting=True)\n",
    "\n",
    "                camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)\n",
    "                camera_pose = np.array([\n",
    "                    [1.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 1.0, 0.0, -1.0],\n",
    "                    [0.0, 0.0, 1.0, 100],\n",
    "                    [0.0, 0.0, 0.0, 1.0]\n",
    "                ])  \n",
    "                scene.add(camera, pose=camera_pose)      \n",
    "                \n",
    "                pyrender.Viewer(scene, use_raymond_lighting=True) \n",
    "            \n",
    "                # r = pyrender.OffscreenRenderer(1280, 720)\n",
    "                # color, depth = r.render(scene)  \n",
    "                # plt.imshow(color)\n",
    "                # r.delete() \n",
    "\n",
    "                # # 构建保存图像的文件名\n",
    "                # file_name = os.path.join(images_directory, f'{os.path.splitext(file)[0]}.png') \n",
    "                \n",
    "                # # 保存图像\n",
    "                # imageio.imwrite(file_name, color) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  default_transl = torch.tensor(transl, dtype=dtype)\n",
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:636: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  default_lhand_pose = torch.tensor(left_hand_pose, dtype=dtype)\n",
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:648: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  default_rhand_pose = torch.tensor(right_hand_pose, dtype=dtype)\n",
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:1023: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  default_jaw_pose = torch.tensor(jaw_pose, dtype=dtype)\n",
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:1032: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  default_leye_pose = torch.tensor(leye_pose, dtype=dtype)\n",
      "/opt/miniconda3/envs/gui/lib/python3.9/site-packages/smplx/body_models.py:1041: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  default_reye_pose = torch.tensor(reye_pose, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices shape = (10475, 3)\n",
      "Joints shape = (127, 3)\n"
     ]
    }
   ],
   "source": [
    "npz_file_path = '/Users/lxy/Desktop/yxl/results/demo00001/smplx/00001_0.npz' \n",
    "data = load_smplx_data(npz_file_path)  \n",
    "  \n",
    "  \n",
    "model_folder = f\"/Users/lxy/Gitlab/smplx/models/smplx/SMPLX_NEUTRAL.npz\"  \n",
    "model_type = 'smplx'\n",
    "gender = 'neutral'\n",
    "use_face_contour = False \n",
    "age = 'adult' \n",
    "num_betas = 10\n",
    "num_expression_coeffs = 10 \n",
    "batch_size = 1 \n",
    "ext = 'npz'\n",
    "\n",
    "sample_shape = None \n",
    "sample_expression = None \n",
    "\n",
    "plotting_module = 'pyrender'  \n",
    "plot_joints = False    \n",
    "\n",
    "sample_shape = None \n",
    "sample_expression = None \n",
    "\n",
    "plotting_module = 'pyrender'  \n",
    "plot_joints = False\n",
    "\n",
    "model = smplx.create(model_folder\n",
    "                     , model_type=model_type\n",
    "                     , gender=gender  \n",
    "                     , global_orient=data['global_orient']\n",
    "                     , body_pose=data['body_pose']\n",
    "                     , leye_pose=data['leye_pose']\n",
    "                     , reye_pose=data['reye_pose'] \n",
    "                     , left_hand_pose=data['left_hand_pose']\n",
    "                     , right_hand_pose=data['right_hand_pose'] \n",
    "                     , jaw_pose=data['jaw_pose'] \n",
    "                     , transl=data['transl']  \n",
    "                     , use_pca=False\n",
    "                     , use_face_contour=use_face_contour\n",
    "                     , num_betas=num_betas\n",
    "                     , num_expression_coeffs=num_expression_coeffs\n",
    "                     , flat_hand_mean=False\n",
    "                     , ext=ext) \n",
    "\n",
    "output = model(global_orient=data['global_orient'], \n",
    "                betas=data['betas'],\n",
    "                expression=data['expression'], return_verts=True)  \n",
    "\n",
    "vertices = output.vertices.detach().cpu().numpy().squeeze()\n",
    "joints = output.joints.detach().cpu().numpy().squeeze()\n",
    "\n",
    "print('Vertices shape =', vertices.shape)\n",
    "print('Joints shape =', joints.shape)\n",
    "\n",
    "if plotting_module == 'pyrender':\n",
    "    import pyrender\n",
    "    import trimesh \n",
    "\n",
    "    vertex_colors = np.ones([vertices.shape[0], 4]) * [0.3, 0.3, 0.3, 0.8]\n",
    "    tri_mesh = trimesh.Trimesh(vertices, model.faces,\n",
    "                                vertex_colors=vertex_colors)\n",
    "\n",
    "    mesh = pyrender.Mesh.from_trimesh(tri_mesh)\n",
    "\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(mesh)\n",
    "\n",
    "    if plot_joints:\n",
    "        sm = trimesh.creation.uv_sphere(radius=0.005)\n",
    "        sm.visual.vertex_colors = [0.9, 0.1, 0.1, 1.0]\n",
    "        tfs = np.tile(np.eye(4), (len(joints), 1, 1))\n",
    "        tfs[:, :3, 3] = joints\n",
    "        joints_pcl = pyrender.Mesh.from_trimesh(sm, poses=tfs)\n",
    "        scene.add(joints_pcl) \n",
    "        \n",
    "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "    camera_pose = np.array([\n",
    "                    [1,     0,     0,      0],\n",
    "                    [0,    -1,     0,      0],\n",
    "                    [0,     0,     1,     20],\n",
    "                    [0,     0,     0,    1.0]\n",
    "                ]) \n",
    "         \n",
    "    pyrender.Viewer(scene, use_raymond_lighting=True) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001/smplx/00034_0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m npz_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001/smplx/00034_0.npz\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m      2\u001b[0m model_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Work/Chinese_CV/CCM/Papers/smplx/models/smplx/SMPLX_NEUTRAL.npz\u001b[39m\u001b[38;5;124m'\u001b[39m    \n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_smplx_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpz_file_path\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m base_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      6\u001b[0m images_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mload_smplx_data\u001b[0;34m(npz_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_smplx_data\u001b[39m(npz_path): \n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpz_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     global_orient \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_orient\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m      6\u001b[0m     body_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody_pose\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gui/lib/python3.9/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001/smplx/00034_0.npz'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "npz_file_path = '/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001/smplx/00034_0.npz'  \n",
    "model_folder = '/Volumes/Work/Chinese_CV/CCM/Papers/smplx/models/smplx/SMPLX_NEUTRAL.npz'    \n",
    "data = load_smplx_data(npz_file_path) \n",
    "\n",
    "base_directory = '/Volumes/Work/Chinese_CV/CCM/Papers/SMPLer-X/demo/results/demo00001' \n",
    "images_directory = os.path.join(base_directory, 'images') \n",
    "\n",
    "model_type = 'smplx'\n",
    "gender = 'neutral'\n",
    "use_face_contour = False \n",
    "age = 'adult' \n",
    "num_betas = 10\n",
    "num_expression_coeffs = 10 \n",
    "batch_size = 1 \n",
    "ext = 'npz'\n",
    "\n",
    "sample_shape = None \n",
    "sample_expression = None \n",
    "\n",
    "plotting_module = 'pyrender'  \n",
    "plot_joints = False  \n",
    "\n",
    "data = load_smplx_data(npz_file_path)  \n",
    "model = smplx.create(model_folder\n",
    "                     , model_type=model_type\n",
    "                     , gender=gender  \n",
    "                     , global_orient=data['global_orient']\n",
    "                     , body_pose=data['body_pose']\n",
    "                     , leye_pose=data['leye_pose']\n",
    "                     , reye_pose=data['reye_pose']  \n",
    "                     , left_hand_pose=data['left_hand_pose']\n",
    "                     , right_hand_pose=data['right_hand_pose']\n",
    "                     , jaw_pose=data['jaw_pose']\n",
    "                     , transl=data['transl'] \n",
    "                     , use_pca=False\n",
    "                     , use_face_contour=use_face_contour\n",
    "                     , num_betas=num_betas\n",
    "                     , num_expression_coeffs=num_expression_coeffs\n",
    "                     , flat_hand_mean=False\n",
    "                     , ext=ext) \n",
    "\n",
    "output = model(global_orient=data['global_orient'], \n",
    "                betas=data['betas'],\n",
    "                expression=data['expression'], return_verts=True)  \n",
    "\n",
    "vertices = output.vertices.detach().cpu().numpy().squeeze()\n",
    "joints = output.joints.detach().cpu().numpy().squeeze()\n",
    "\n",
    "print('Vertices shape =', vertices.shape)\n",
    "print('Joints shape =', joints.shape)\n",
    "\n",
    "if plotting_module == 'pyrender':\n",
    "    import pyrender\n",
    "    import trimesh \n",
    "\n",
    "    vertex_colors = np.ones([vertices.shape[0], 4]) * [0.3, 0.3, 0.3, 0.8]\n",
    "    tri_mesh = trimesh.Trimesh(vertices, model.faces,\n",
    "                                vertex_colors=vertex_colors)\n",
    "\n",
    "    mesh = pyrender.Mesh.from_trimesh(tri_mesh)\n",
    "\n",
    "    scene = pyrender.Scene()\n",
    "    scene.add(mesh)\n",
    "\n",
    "    if plot_joints:  \n",
    "        sm = trimesh.creation.uv_sphere(radius=0.005)\n",
    "        sm.visual.vertex_colors = [0.9, 0.1, 0.1, 1.0]\n",
    "        tfs = np.tile(np.eye(4), (len(joints), 1, 1))\n",
    "        tfs[:, :3, 3] = joints\n",
    "        joints_pcl = pyrender.Mesh.from_trimesh(sm, poses=tfs)\n",
    "        scene.add(joints_pcl) \n",
    "\n",
    "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0 )\n",
    "    camera_node = pyrender.Node(camera=camera)  \n",
    "    scene.add_node(camera_node)  \n",
    "\n",
    "    camera_pose = np.array([\n",
    "        [1,     0,     0,      0],\n",
    "        [0,    -1,     0,      -1],\n",
    "        [0,     0,     1,     28],\n",
    "        [0,     0,     0,    1.0]\n",
    "    ]) \n",
    "\n",
    "    # 设置相机的位置和方向 \n",
    "    scene.set_pose(camera_node, pose=camera_pose) \n",
    "    scene.add(camera, pose=camera_pose)  \n",
    "\n",
    "    pyrender.Viewer(scene, use_raymond_lighting=True) \n",
    "\n",
    "    # Print camera matrix\n",
    "    print(\"Camera pose:\\n\", camera_pose)\n",
    "\n",
    "    # r = pyrender.OffscreenRenderer(1280, 720)\n",
    "    # color, depth = r.render(scene) \n",
    "    # plt.figure(dpi=300)\n",
    "    # plt.axis('off')\n",
    "    # plt.imshow(color) \n",
    "\n",
    "    # r = pyrender.OffscreenRenderer(1280, 720) \n",
    "    # color, depth = r.render(scene)   \n",
    "    # plt.figure(figsize=(18,12))    \n",
    "    # plt.imshow(color)  \n",
    "    # plt.axis('off')\n",
    "    # r.delete() \n",
    "\n",
    "    # 构建保存图像的文件名\n",
    "    # file_name = os.path.join(images_directory, f'{os.path.splitext(file)[0]}.png') \n",
    "    \n",
    "    # 保存图像 \n",
    "    # imageio.imwrite(file_name, color)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smplerx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
